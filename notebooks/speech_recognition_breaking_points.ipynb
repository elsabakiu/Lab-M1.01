{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "header-main",
      "metadata": {},
      "source": [
        "# üéØ Speech Recognition Breaking Points\n",
        "\n",
        "## Goal\n",
        "Find out what makes speech recognition fail by testing various challenging conditions.\n",
        "\n",
        "## Overview\n",
        "We'll test speech recognition accuracy under different conditions:\n",
        "- Normal speaking (baseline)\n",
        "- Fast talking\n",
        "- Background noise\n",
        "\n",
        "By the end, you'll understand which conditions cause the most errors and why!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "setup",
      "metadata": {},
      "source": [
        "## üì¶ Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "install-deps",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sounddevice in /Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages (0.5.5)\n",
            "Requirement already satisfied: numpy in /Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages (2.1.3)\n",
            "Collecting scipy\n",
            "  Using cached scipy-1.17.0-cp311-cp311-macosx_10_14_x86_64.whl.metadata (62 kB)\n",
            "Collecting openai\n",
            "  Downloading openai-2.17.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: matplotlib in /Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages (3.10.1)\n",
            "Collecting pandas\n",
            "  Downloading pandas-3.0.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (79 kB)\n",
            "Collecting seaborn\n",
            "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: librosa in /Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages (0.11.0)\n",
            "Requirement already satisfied: soundfile in /Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages (0.13.1)\n",
            "Requirement already satisfied: cffi in /Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages (from sounddevice) (2.0.0)\n",
            "Collecting anyio<5,>=3.5.0 (from openai)\n",
            "  Using cached anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting distro<2,>=1.7.0 (from openai)\n",
            "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.10.0 (from openai)\n",
            "  Downloading jiter-0.13.0-cp311-cp311-macosx_10_12_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting pydantic<3,>=1.9.0 (from openai)\n",
            "  Using cached pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
            "Collecting sniffio (from openai)\n",
            "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting tqdm>4 (from openai)\n",
            "  Using cached tqdm-4.67.3-py3-none-any.whl.metadata (57 kB)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.41.5 (from pydantic<3,>=1.9.0->openai)\n",
            "  Downloading pydantic_core-2.41.5-cp311-cp311-macosx_10_12_x86_64.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspection>=0.4.2 (from pydantic<3,>=1.9.0->openai)\n",
            "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages (from matplotlib) (26.0)\n",
            "Requirement already satisfied: pillow>=8 in /Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages (from matplotlib) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages (from librosa) (0.61.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages (from librosa) (1.8.0)\n",
            "Requirement already satisfied: joblib>=1.0 in /Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages (from librosa) (1.5.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages (from librosa) (5.2.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages (from librosa) (1.9.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages (from librosa) (1.0.0)\n",
            "Collecting lazy_loader>=0.1 (from librosa)\n",
            "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: msgpack>=1.0 in /Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages (from librosa) (1.1.2)\n",
            "Requirement already satisfied: pycparser in /Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages (from cffi->sounddevice) (3.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages (from pooch>=1.1->librosa) (4.5.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages (from pooch>=1.1->librosa) (2.32.5)\n",
            "Requirement already satisfied: six>=1.5 in /Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.2.0 in /Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Using cached scipy-1.17.0-cp311-cp311-macosx_10_14_x86_64.whl (31.4 MB)\n",
            "Downloading openai-2.17.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached anyio-4.12.1-py3-none-any.whl (113 kB)\n",
            "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
            "Downloading jiter-0.13.0-cp311-cp311-macosx_10_12_x86_64.whl (311 kB)\n",
            "Using cached pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
            "Downloading pydantic_core-2.41.5-cp311-cp311-macosx_10_12_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-3.0.0-cp311-cp311-macosx_10_9_x86_64.whl (10.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
            "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
            "Using cached tqdm-4.67.3-py3-none-any.whl (78 kB)\n",
            "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
            "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: typing-inspection, tqdm, sniffio, scipy, pydantic-core, lazy_loader, jiter, h11, distro, anyio, annotated-types, pydantic, pandas, httpcore, seaborn, httpx, openai\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m17/17\u001b[0m [openai]16/17\u001b[0m [openai]]]er]\n",
            "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 anyio-4.12.1 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 jiter-0.13.0 lazy_loader-0.4 openai-2.17.0 pandas-3.0.0 pydantic-2.12.5 pydantic-core-2.41.5 scipy-1.17.0 seaborn-0.13.2 sniffio-1.3.1 tqdm-4.67.3 typing-inspection-0.4.2\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install sounddevice numpy scipy openai matplotlib pandas seaborn librosa soundfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "imports",
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'dotenv'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlibrosa\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msoundfile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msf\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[32m     20\u001b[39m load_dotenv()\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Set up OpenAI client\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'dotenv'"
          ]
        }
      ],
      "source": [
        "import sounddevice as sd\n",
        "import numpy as np\n",
        "import scipy.io.wavfile as wavfile\n",
        "from openai import OpenAI\n",
        "import io\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import Audio, display, Markdown\n",
        "import time\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "import soundfile as sf\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Set up OpenAI client\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "# Create directories for storing recordings\n",
        "os.makedirs('recordings', exist_ok=True)\n",
        "os.makedirs('results', exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ Setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "test-sentences",
      "metadata": {},
      "source": [
        "## üìù Step 1: Select Test Sentences\n",
        "\n",
        "We'll use 5 carefully chosen sentences that test different aspects of speech recognition:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "define-sentences",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test sentences with different challenges\n",
        "test_sentences = [\n",
        "    \"The quick brown fox jumps over the lazy dog\",  # Classic pangram\n",
        "    \"She sells seashells by the seashore\",  # Tongue twister with similar sounds\n",
        "    \"The weather whether we like it or not affects our mood\",  # Homophones\n",
        "    \"I scream you scream we all scream for ice cream\",  # Fast repetitive sounds\n",
        "    \"Dr Smith's laboratory analyzed 1234 samples at 3:45 PM\",  # Numbers, abbreviations, punctuation\n",
        "]\n",
        "\n",
        "# Display the sentences nicely\n",
        "display(Markdown(\"### Test Sentences:\"))\n",
        "for i, sentence in enumerate(test_sentences, 1):\n",
        "    print(f\"{i}. {sentence}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "recording-functions",
      "metadata": {},
      "source": [
        "## üé§ Step 2: Recording Functions\n",
        "\n",
        "Let's create functions to record audio under different conditions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "recording-utils",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Recording functions ready!\n"
          ]
        }
      ],
      "source": [
        "def record_audio(duration=5, sample_rate=16000, condition=\"normal\"):\n",
        "    \"\"\"\n",
        "    Record audio with visual countdown\n",
        "    \"\"\"\n",
        "    print(f\"\\nüé§ Recording Mode: {condition.upper()}\")\n",
        "    print(\"Get ready...\")\n",
        "    time.sleep(2)\n",
        "    \n",
        "    # Countdown\n",
        "    for i in range(3, 0, -1):\n",
        "        print(f\"Starting in {i}...\")\n",
        "        time.sleep(1)\n",
        "    \n",
        "    print(f\"üî¥ RECORDING! Speak now for {duration} seconds!\")\n",
        "    \n",
        "    # Record audio\n",
        "    audio = sd.rec(int(duration * sample_rate), \n",
        "                   samplerate=sample_rate, \n",
        "                   channels=1, \n",
        "                   dtype='float32')\n",
        "    sd.wait()\n",
        "    \n",
        "    print(\"‚úÖ Recording complete!\")\n",
        "    return audio.flatten(), sample_rate\n",
        "\n",
        "\n",
        "def add_background_noise(audio, noise_level=0.05):\n",
        "    \"\"\"\n",
        "    Add synthetic background noise to audio\n",
        "    \"\"\"\n",
        "    noise = np.random.normal(0, noise_level, audio.shape)\n",
        "    return audio + noise\n",
        "\n",
        "\n",
        "def save_recording(audio, sample_rate, filename):\n",
        "    \"\"\"\n",
        "    Save audio to WAV file\n",
        "    \"\"\"\n",
        "    # Normalize audio to prevent clipping\n",
        "    audio = np.clip(audio, -1, 1)\n",
        "    audio_int16 = (audio * 32767).astype(np.int16)\n",
        "    wavfile.write(filename, sample_rate, audio_int16)\n",
        "    return filename\n",
        "\n",
        "\n",
        "def visualize_waveform(audio, sample_rate, title=\"Audio Waveform\"):\n",
        "    \"\"\"\n",
        "    Display the waveform of recorded audio\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 3))\n",
        "    time_axis = np.linspace(0, len(audio) / sample_rate, len(audio))\n",
        "    plt.plot(time_axis, audio)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Time (seconds)')\n",
        "    plt.ylabel('Amplitude')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "print(\"‚úÖ Recording functions ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "recording-instructions",
      "metadata": {},
      "source": [
        "## üé¨ Step 3: Record Test Sentences\n",
        "\n",
        "### Recording Instructions:\n",
        "\n",
        "#### üéØ Normal Recording\n",
        "- Quiet room\n",
        "- Clear, moderate pace\n",
        "- Natural speaking voice\n",
        "\n",
        "#### ‚ö° Fast Talking\n",
        "- Speak as quickly as you can\n",
        "- Still try to be clear\n",
        "- Like you're in a rush!\n",
        "\n",
        "#### üîä Background Noise\n",
        "- Play music or TV in background\n",
        "- Or record near a window with traffic\n",
        "- Or have someone talk nearby"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "recording-loop",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize storage for all recordings\n",
        "all_recordings = []\n",
        "recording_metadata = []\n",
        "\n",
        "conditions = ['normal', 'fast', 'noisy']\n",
        "sample_rate = 16000\n",
        "duration = 5  # seconds per recording\n",
        "\n",
        "# Instructions for each condition\n",
        "condition_instructions = {\n",
        "    'normal': \"üìç Speak clearly at a normal pace in a quiet environment\",\n",
        "    'fast': \"‚ö° Speak as fast as you can while still being clear\",\n",
        "    'noisy': \"üîä Speak normally but with background noise (TV, music, or talking)\"\n",
        "}\n",
        "\n",
        "# Record each sentence under each condition\n",
        "for sentence_idx, sentence in enumerate(test_sentences):\n",
        "    display(Markdown(f\"\\n### üìù Sentence {sentence_idx + 1}: *\\\"{sentence}\\\"*\"))\n",
        "    \n",
        "    for condition in conditions:\n",
        "        display(Markdown(f\"\\n**Condition: {condition.upper()}**\"))\n",
        "        print(condition_instructions[condition])\n",
        "        \n",
        "        # Wait for user to be ready\n",
        "        input(f\"\\nPress ENTER when ready to record ({condition} version)...\")\n",
        "        \n",
        "        # Record audio\n",
        "        audio, sr = record_audio(duration, sample_rate, condition)\n",
        "        \n",
        "        # Add synthetic noise if needed (optional - for testing without real noise)\n",
        "        if condition == 'noisy' and input(\"Add synthetic noise? (y/n): \").lower() == 'y':\n",
        "            audio = add_background_noise(audio, noise_level=0.08)\n",
        "        \n",
        "        # Save recording\n",
        "        filename = f\"recordings/sentence{sentence_idx+1}_{condition}.wav\"\n",
        "        save_recording(audio, sr, filename)\n",
        "        \n",
        "        # Store metadata\n",
        "        recording_metadata.append({\n",
        "            'sentence_id': sentence_idx + 1,\n",
        "            'original_text': sentence,\n",
        "            'condition': condition,\n",
        "            'filename': filename,\n",
        "            'timestamp': datetime.now().isoformat()\n",
        "        })\n",
        "        \n",
        "        # Display waveform\n",
        "        visualize_waveform(audio, sr, f\"Sentence {sentence_idx+1} - {condition.upper()}\")\n",
        "        \n",
        "        # Let user listen to their recording\n",
        "        display(Audio(audio, rate=sr))\n",
        "        \n",
        "        print(\"‚úÖ Saved!\\n\")\n",
        "\n",
        "print(f\"\\nüéâ All {len(recording_metadata)} recordings complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "transcription",
      "metadata": {},
      "source": [
        "## ü§ñ Step 4: Run Speech Recognition\n",
        "\n",
        "Now let's transcribe all recordings using Whisper API:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "transcribe-all",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ü§ñ Starting transcription...\n",
            "\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'recording_metadata' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mü§ñ Starting transcription...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     19\u001b[39m results = []\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m metadata \u001b[38;5;129;01min\u001b[39;00m \u001b[43mrecording_metadata\u001b[49m:\n\u001b[32m     22\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTranscribing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetadata[\u001b[33m'\u001b[39m\u001b[33mfilename\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m     \u001b[38;5;66;03m# Get transcription\u001b[39;00m\n",
            "\u001b[31mNameError\u001b[39m: name 'recording_metadata' is not defined"
          ]
        }
      ],
      "source": [
        "def transcribe_audio(filename, client):\n",
        "    \"\"\"\n",
        "    Transcribe audio file using OpenAI Whisper API\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(filename, 'rb') as audio_file:\n",
        "            transcript = client.audio.transcriptions.create(\n",
        "                model=\"whisper-1\",\n",
        "                file=audio_file,\n",
        "                response_format=\"text\"\n",
        "            )\n",
        "        return transcript.strip()\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "\n",
        "# Transcribe all recordings\n",
        "print(\"ü§ñ Starting transcription...\\n\")\n",
        "results = []\n",
        "\n",
        "for metadata in recording_metadata:\n",
        "    print(f\"Transcribing: {metadata['filename']}...\")\n",
        "    \n",
        "    # Get transcription\n",
        "    transcription = transcribe_audio(metadata['filename'], client)\n",
        "    \n",
        "    # Calculate basic accuracy (word-level)\n",
        "    original_words = metadata['original_text'].lower().split()\n",
        "    transcribed_words = transcription.lower().split()\n",
        "    \n",
        "    # Simple word accuracy calculation\n",
        "    correct_words = 0\n",
        "    for i, word in enumerate(original_words):\n",
        "        if i < len(transcribed_words) and word == transcribed_words[i]:\n",
        "            correct_words += 1\n",
        "    \n",
        "    accuracy = (correct_words / len(original_words)) * 100 if original_words else 0\n",
        "    \n",
        "    # Store results\n",
        "    result = {\n",
        "        'sentence_id': metadata['sentence_id'],\n",
        "        'condition': metadata['condition'],\n",
        "        'original': metadata['original_text'],\n",
        "        'transcription': transcription,\n",
        "        'word_accuracy': round(accuracy, 2),\n",
        "        'exact_match': metadata['original_text'].lower() == transcription.lower()\n",
        "    }\n",
        "    results.append(result)\n",
        "    \n",
        "    print(f\"‚úÖ Done! Accuracy: {accuracy:.1f}%\\n\")\n",
        "\n",
        "print(\"\\nüéâ All transcriptions complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "analysis",
      "metadata": {},
      "source": [
        "## üìä Step 5: Analyze Results\n",
        "\n",
        "Let's compare the transcriptions and find patterns:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "display-results",
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'sentence_id'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Display results for each sentence\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sentence_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m6\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     sentence_results = df_results[\u001b[43mdf_results\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msentence_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m == sentence_id]\n\u001b[32m      7\u001b[39m     original = sentence_results.iloc[\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33moriginal\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      9\u001b[39m     display(Markdown(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m### Sentence \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msentence_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: *\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00moriginal\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m*\u001b[39m\u001b[33m\"\u001b[39m))\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py311env/lib/python3.11/site-packages/pandas/core/frame.py:4378\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4376\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4377\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4378\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4379\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4380\u001b[39m     indexer = [indexer]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py311env/lib/python3.11/site-packages/pandas/core/indexes/range.py:525\u001b[39m, in \u001b[36mRangeIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    523\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    524\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[32m    526\u001b[39m \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
            "\u001b[31mKeyError\u001b[39m: 'sentence_id'"
          ]
        }
      ],
      "source": [
        "# Create a DataFrame for easier analysis\n",
        "df_results = pd.DataFrame(results)\n",
        "\n",
        "# Display results for each sentence\n",
        "for sentence_id in range(1, 6):\n",
        "    sentence_results = df_results[df_results['sentence_id'] == sentence_id]\n",
        "    original = sentence_results.iloc[0]['original']\n",
        "    \n",
        "    display(Markdown(f\"\\n### Sentence {sentence_id}: *\\\"{original}\\\"*\"))\n",
        "    \n",
        "    for _, row in sentence_results.iterrows():\n",
        "        status = \"‚úÖ\" if row['exact_match'] else \"‚ö†Ô∏è\"\n",
        "        print(f\"\\n{status} {row['condition'].upper()}:\")\n",
        "        print(f\"   Transcription: \\\"{row['transcription']}\\\"\")\n",
        "        print(f\"   Word Accuracy: {row['word_accuracy']}%\")\n",
        "        \n",
        "        # Highlight differences\n",
        "        if not row['exact_match']:\n",
        "            original_words = original.lower().split()\n",
        "            transcribed_words = row['transcription'].lower().split()\n",
        "            \n",
        "            # Find mismatched words\n",
        "            mismatches = []\n",
        "            for i, orig_word in enumerate(original_words):\n",
        "                if i >= len(transcribed_words):\n",
        "                    mismatches.append(f\"Missing: '{orig_word}'\")\n",
        "                elif orig_word != transcribed_words[i]:\n",
        "                    mismatches.append(f\"'{orig_word}' ‚Üí '{transcribed_words[i]}'\")\n",
        "            \n",
        "            if mismatches:\n",
        "                print(f\"   Errors: {', '.join(mismatches[:3])}\")  # Show first 3 errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "statistical-analysis",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistical Analysis\n",
        "display(Markdown(\"## üìà Statistical Summary\"))\n",
        "\n",
        "# Calculate average accuracy by condition\n",
        "condition_stats = df_results.groupby('condition').agg({\n",
        "    'word_accuracy': ['mean', 'std', 'min', 'max'],\n",
        "    'exact_match': 'mean'\n",
        "}).round(2)\n",
        "\n",
        "print(\"\\nAccuracy by Condition:\")\n",
        "print(condition_stats)\n",
        "\n",
        "# Calculate average accuracy by sentence\n",
        "sentence_stats = df_results.groupby('sentence_id').agg({\n",
        "    'word_accuracy': 'mean',\n",
        "    'exact_match': 'mean'\n",
        "}).round(2)\n",
        "\n",
        "print(\"\\nAccuracy by Sentence:\")\n",
        "for idx, row in sentence_stats.iterrows():\n",
        "    print(f\"Sentence {idx}: {row['word_accuracy']}% accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "visualizations",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create visualizations\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# 1. Accuracy by Condition\n",
        "condition_means = df_results.groupby('condition')['word_accuracy'].mean()\n",
        "ax1 = axes[0, 0]\n",
        "bars1 = ax1.bar(condition_means.index, condition_means.values, \n",
        "                color=['green', 'orange', 'red'])\n",
        "ax1.set_title('Average Accuracy by Condition', fontsize=14, fontweight='bold')\n",
        "ax1.set_xlabel('Condition')\n",
        "ax1.set_ylabel('Word Accuracy (%)')\n",
        "ax1.set_ylim(0, 100)\n",
        "for bar, val in zip(bars1, condition_means.values):\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
        "             f'{val:.1f}%', ha='center', va='bottom')\n",
        "\n",
        "# 2. Accuracy by Sentence\n",
        "sentence_means = df_results.groupby('sentence_id')['word_accuracy'].mean()\n",
        "ax2 = axes[0, 1]\n",
        "bars2 = ax2.bar(sentence_means.index, sentence_means.values, color='steelblue')\n",
        "ax2.set_title('Average Accuracy by Sentence', fontsize=14, fontweight='bold')\n",
        "ax2.set_xlabel('Sentence ID')\n",
        "ax2.set_ylabel('Word Accuracy (%)')\n",
        "ax2.set_ylim(0, 100)\n",
        "for bar, val in zip(bars2, sentence_means.values):\n",
        "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
        "             f'{val:.1f}%', ha='center', va='bottom')\n",
        "\n",
        "# 3. Heatmap of Accuracy\n",
        "pivot_table = df_results.pivot(index='sentence_id', \n",
        "                               columns='condition', \n",
        "                               values='word_accuracy')\n",
        "ax3 = axes[1, 0]\n",
        "sns.heatmap(pivot_table, annot=True, fmt='.1f', cmap='RdYlGn', \n",
        "            vmin=0, vmax=100, ax=ax3, cbar_kws={'label': 'Accuracy (%)'})\n",
        "ax3.set_title('Accuracy Heatmap: Sentence vs Condition', fontsize=14, fontweight='bold')\n",
        "ax3.set_xlabel('Condition')\n",
        "ax3.set_ylabel('Sentence ID')\n",
        "\n",
        "# 4. Error Distribution\n",
        "ax4 = axes[1, 1]\n",
        "conditions_data = [df_results[df_results['condition'] == c]['word_accuracy'].values \n",
        "                   for c in conditions]\n",
        "bp = ax4.boxplot(conditions_data, labels=conditions, patch_artist=True)\n",
        "colors = ['lightgreen', 'lightyellow', 'lightcoral']\n",
        "for patch, color in zip(bp['boxes'], colors):\n",
        "    patch.set_facecolor(color)\n",
        "ax4.set_title('Accuracy Distribution by Condition', fontsize=14, fontweight='bold')\n",
        "ax4.set_xlabel('Condition')\n",
        "ax4.set_ylabel('Word Accuracy (%)')\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('results/accuracy_analysis.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüìä Visualizations saved to 'results/accuracy_analysis.png'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "findings",
      "metadata": {},
      "source": [
        "## üîç Step 6: Key Findings & Patterns\n",
        "\n",
        "Based on your results, answer these questions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "analyze-patterns",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Automated pattern detection\n",
        "display(Markdown(\"### üéØ Automated Pattern Analysis\"))\n",
        "\n",
        "# 1. Which condition caused the most errors?\n",
        "worst_condition = condition_means.idxmin()\n",
        "best_condition = condition_means.idxmax()\n",
        "\n",
        "print(f\"\\nüìâ **Worst Condition:** {worst_condition.upper()}\")\n",
        "print(f\"   Average accuracy: {condition_means[worst_condition]:.1f}%\")\n",
        "print(f\"\\nüìà **Best Condition:** {best_condition.upper()}\")\n",
        "print(f\"   Average accuracy: {condition_means[best_condition]:.1f}%\")\n",
        "\n",
        "# 2. Which sentence was hardest to recognize?\n",
        "hardest_sentence = sentence_means.idxmin()\n",
        "easiest_sentence = sentence_means.idxmax()\n",
        "\n",
        "print(f\"\\nüî¥ **Hardest Sentence:** #{hardest_sentence}\")\n",
        "print(f\"   \\\"{test_sentences[hardest_sentence-1]}\\\"\")\n",
        "print(f\"   Average accuracy: {sentence_means[hardest_sentence]:.1f}%\")\n",
        "\n",
        "print(f\"\\nüü¢ **Easiest Sentence:** #{easiest_sentence}\")\n",
        "print(f\"   \\\"{test_sentences[easiest_sentence-1]}\\\"\")\n",
        "print(f\"   Average accuracy: {sentence_means[easiest_sentence]:.1f}%\")\n",
        "\n",
        "# 3. Perfect transcriptions\n",
        "perfect_count = df_results['exact_match'].sum()\n",
        "total_count = len(df_results)\n",
        "print(f\"\\n‚ú® **Perfect Transcriptions:** {perfect_count}/{total_count} ({perfect_count/total_count*100:.1f}%)\")\n",
        "\n",
        "# 4. Accuracy drop from normal to challenging conditions\n",
        "normal_acc = condition_means['normal']\n",
        "fast_acc = condition_means['fast']\n",
        "noisy_acc = condition_means['noisy']\n",
        "\n",
        "print(f\"\\nüìä **Impact of Conditions:**\")\n",
        "print(f\"   Fast talking reduced accuracy by: {normal_acc - fast_acc:.1f}%\")\n",
        "print(f\"   Background noise reduced accuracy by: {normal_acc - noisy_acc:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "conclusions",
      "metadata": {},
      "source": [
        "## üí° Conclusions & Insights\n",
        "\n",
        "### Write Your Findings Here:\n",
        "\n",
        "Based on your experiment, answer these questions:\n",
        "\n",
        "1. **What patterns did you notice?**\n",
        "   - Which types of words were most often misheard?\n",
        "   - Were certain sounds consistently problematic?\n",
        "\n",
        "2. **Why do you think certain conditions caused more errors?**\n",
        "   - Think about how noise masks certain frequencies\n",
        "   - Consider how fast speech affects word boundaries\n",
        "\n",
        "3. **What surprised you about the results?**\n",
        "\n",
        "4. **How could speech recognition be improved?**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py311env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
