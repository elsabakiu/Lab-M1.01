{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deep Learning Examples\n",
        "\n",
        "**Note: Run this notebook in Google Colab for best compatibility.**\n",
        "\n",
        "This notebook demonstrates neural networks and transformers using TensorFlow/Keras and Hugging Face.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Three-Layer Neural Network\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Data Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "x_train = x_train.reshape((x_train.shape[0], 28 * 28))\n",
        "x_test = x_test.reshape((x_test.shape[0], 28 * 28))\n",
        "\n",
        "print(f\"Training samples: {x_train.shape[0]}\")\n",
        "print(f\"Test samples: {x_test.shape[0]}\")\n",
        "print(f\"Feature dimensions: {x_train.shape[1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Model Architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation='relu', input_shape=(784,)),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3 Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.4 Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test loss: {test_loss:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Model Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Model Loss')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Transformer for Zero-Shot Sentiment Classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Setup and Model Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install transformers torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"zero-shot-classification\", \n",
        "                     model=\"facebook/bart-large-mnli\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Zero-Shot Classification Examples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "candidate_labels = [\"positive\", \"negative\", \"neutral\"]\n",
        "\n",
        "text1 = \"I absolutely love this product! It's amazing!\"\n",
        "result1 = classifier(text1, candidate_labels)\n",
        "print(f\"Text: {text1}\")\n",
        "print(f\"Labels: {result1['labels']}\")\n",
        "print(f\"Scores: {result1['scores']}\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text2 = \"This is the worst experience I've ever had.\"\n",
        "result2 = classifier(text2, candidate_labels)\n",
        "print(f\"Text: {text2}\")\n",
        "print(f\"Labels: {result2['labels']}\")\n",
        "print(f\"Scores: {result2['scores']}\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text3 = \"The weather is okay today, nothing special.\"\n",
        "result3 = classifier(text3, candidate_labels)\n",
        "print(f\"Text: {text3}\")\n",
        "print(f\"Labels: {result3['labels']}\")\n",
        "print(f\"Scores: {result3['scores']}\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Batch Classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "texts = [\n",
        "    \"This movie is fantastic!\",\n",
        "    \"I hate waiting in long lines.\",\n",
        "    \"The service was acceptable.\",\n",
        "    \"Best purchase I've made this year!\",\n",
        "    \"Terrible quality, very disappointed.\"\n",
        "]\n",
        "\n",
        "results = classifier(texts, candidate_labels)\n",
        "\n",
        "for i, (text, result) in enumerate(zip(texts, results)):\n",
        "    print(f\"Text {i+1}: {text}\")\n",
        "    print(f\"Predicted: {result['labels'][0]} (score: {result['scores'][0]:.4f})\")\n",
        "    print()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}